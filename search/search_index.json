{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About Me","text":""},{"location":"#automate-your-business-processes-reduce-errors-time-and-costs","title":"Automate your business processes. Reduce errors, time, and costs.","text":""},{"location":"#simplify-your-teams-work-with-automation-solutions-tailored-to-your-company","title":"Simplify your team\u2019s work with automation solutions tailored to your company.","text":"<p>Are you still managing processes with Excel, emails, paperwork, or countless unnecessary clicks? With over 20 years of experience in software development, I help manufacturing and industrial companies optimize and automate their workflows, cutting down on repetitive tasks, human errors, and hidden costs.</p>"},{"location":"#about-me","title":"\ud83d\udc68\u200d\ud83d\udcbb About Me","text":"<p>I\u2019m a freelance software engineer with more than 20 years of experience in small businesses, mid-sized companies, and multinationals. I speak both the language of entrepreneurs and of technical teams, and I know how to turn complex needs into concrete solutions.</p>"},{"location":"#what-i-can-do-for-you","title":"\u2705 What I can do for you:","text":"<ul> <li> <p> Data Entry</p> <p>AI Agents automations for order and document management to save time and minimize errors.</p> </li> <li> <p> Document workflows:</p> <p>Build smart approval workflows for vacations, expenses, and technical changes.</p> </li> <li> <p> Manufacturing </p> <p>Connect your ERP or management system with other tools via APIs, custom integrations, or low-code platforms.</p> </li> <li> <p> Data analysis &amp; visualization </p> <p>Provide dashboards and alerts to monitor real-time data\u2014production, sales, administration, and finance.</p> </li> </ul>"},{"location":"#want-to-see-if-we-can-work-together","title":"\ud83d\udcde Want to see if we can work together?","text":"<p>Book a short introductory call: i\u2019ll listen to you, ask a few questions, and explain how I could help\u2014no commitment required.</p> Book a call"},{"location":"#frequently-asked-questions","title":"Frequently asked questions","text":"How quickly can you start working on my project? <p>I can typically begin new projects within 1-2 weeks of contract signing. For urgent matters, I maintain some flexibility for rapid response situations and can potentially start sooner - just let me know your timeline during our initial consultation.</p> Do you require a minimum project size or commitment? <p>While I can accommodate projects of any size, I find that engagements of at least 20 hours allow for meaningful impact. This gives us enough time to understand your data, implement solutions, and deliver actionable results. We can start with a small pilot project to ensure we're a good fit.</p> What industries do you have experience in? <p>I've successfully delivered projects across manufacturing, R&amp;D, and engineering services. While I specialize in Software Engineering fundamentals that apply across sectors, I particularly excel in projects involving data entry, workflows optimization, and data analysis and presentation.</p> How do you handle data security and confidentiality? <p>I take data security extremely seriously. I sign comprehensive NDAs before starting any project, use enterprise-grade encryption for all data transfers, and follow industry best practices for data handling. I can also work within your existing security infrastructure and policies.</p> What's your pricing structure? <p>I offer both project-based and retainer pricing models. Project fees are based on scope, complexity, and value delivered rather than hours worked. For ongoing support, I offer flexible retainer packages. Let's discuss your specific needs during our consultation to determine the most cost-effective approach.</p> How do you communicate progress and results? <p>I maintain clear communication through weekly progress updates and regular check-in meetings. You'll receive detailed documentation of all analyses, findings, and recommendations. For ongoing projects, I provide interactive dashboards and reports that allow you to track progress and results in real-time.</p> <ul> <li> <p> Let's have a virtual coffee together!</p> <p>Want to see if we're a match? Let's have a chat and find out. Schedule a free 30-minute strategy session to discuss your AI challenges and explore how we can work together.</p> <p>Book Free Intro Call </p> </li> </ul>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2025/09/24/lai-aiuta-davvero-gli-sviluppatori/","title":"L'AI aiuta davvero gli sviluppatori?","text":"<p>Questa \u00e8 la domanda a cui alcuni ricercatori dell'Universit\u00e0 di Stanford hanno cercato di rispondere in questo studio:  \"This is the Does AI Actually Boost Developer Productivity? (100k Devs Study) - Yegor Denisov-Blanch, Stanford.</p> <p>Mark Zuckerberg dichiar\u00f2 all'inizio del 2024 che Meta avrebbe sostituito tutti gli ingegneri di medio livello con AI entro l\u2019anno, Questa affermazione \u00e8 stata percepita da molti come una delle solite \"frasi forti\", da guru dei social media, per tenere alto il valore dei titoli in borsa.</p> <p>Ma per molti \u00e8 stata anche una provocazione: a che punto siamo con l\u2019adozione dell\u2019AI per sostituire sviluppatori?</p>"},{"location":"blog/2025/09/24/lai-aiuta-davvero-gli-sviluppatori/#lo-studio-di-stanford","title":"Lo studio di Stanford","text":"<p>L'Universit\u00e0 di Stanford ha realizzato un interessante studio durato tre anni sulla produttivit\u00e0 degli sviluppatori SW.</p> <p>Questa ricerca si basa su:</p> <ul> <li>serie di dati storici (analisi storica su base Git), compreso l\u2019impatto di eventi come Covid e AI.</li> <li>oltre 600 aziende partecipanti (grandi, medie, startup)</li> <li>100.000+ ingegneri, </li> <li>milioni di commit, miliardi di righe di codice.</li> <li>Dataset composto in gran parte da repository privati, quindi pi\u00f9 rappresentativi e affidabili per misurare la produttivit\u00e0 reale.</li> </ul> <p>Una delle cose pi\u00f9 curiose che sono state scoperte analizzando questi dati \u00e8 che circa il 10% degli ingegneri in analisi non produce lavoro (\"ghost engineers\"), pur percependo uno stipendio.</p>"},{"location":"blog/2025/09/24/lai-aiuta-davvero-gli-sviluppatori/#limiti-degli-studi-precedenti","title":"Limiti degli studi precedenti","text":"<p>Esistono gi\u00e0 alcune ricerche su questo argomento, ma spesso sono condotte dalle stesse aziende che producono i tools AI, con evidenti conflitti di interesse.</p> <p>Le tre principali limitazioni degli attuali studi sono le seguenti:</p> <ul> <li>Metriche superficiali (numero di commit, PR, ecc.): non riflettono la reale produttivit\u00e0, e spesso includono fix ai bug introdotti dagli stessi algoritmi di AI.</li> <li>Esperimenti su greenfield tasks: mostrano che l'AI \u00e8 molto forte quando si scrive codice \u201cda zero\u201d o codice \"boilerplate\", ma sono poco rappresentativi della realt\u00e0 (dove lo sviluppatore deve spesso affrontare progetti \"brownfield\", cio\u00e8 su una base di codice preesistente).</li> <li>Sondaggi di autovalutazione: scarsissima correlazione con la produttivit\u00e0 reale (errore medio di 30 percentili). Sono Utili per il morale e e la percezione, ma non per misurare la produttivit\u00e0.</li> </ul>"},{"location":"blog/2025/09/24/lai-aiuta-davvero-gli-sviluppatori/#la-nuova-metodologia-proposta","title":"La nuova metodologia proposta","text":"<p>Nel mondo ideale, la cosa migliore sarebbe quella di far valutare il codice da parte di un panel di esperti (qualit\u00e0, manutenibilit\u00e0, output). Il problema \u00e8 che questo metodo \u00e8 lento, costoso e non scalabile. </p> <p>La soluzione di Stanford: un modello automatico istruito da un panel di esperti, collegato a Git, che analizza ogni commit e ne valuta il contributo in termini di funzionalit\u00e0, refactoring, rework, ecc.</p> <p>Risultato: una dashboard scalabile e precisa per misurare produttivit\u00e0 a livello di team o azienda:</p> <p></p>"},{"location":"blog/2025/09/24/lai-aiuta-davvero-gli-sviluppatori/#risultati-principali","title":"Risultati principali","text":"<p>La produzione di codice cresce globalmente del 30\u201340%, ma include molto rework (cio\u00e8 correzioni e riscrittura di codice recente) e fix a bug generati dall\u2019AI. Quindi l'aumento di produttivit\u00e0 medio con AI \u00e8 di circa il 15\u201320%.</p> <p>Distribuzione dei guadagni:</p> <ul> <li>Tasks semplici: guadagni maggiori.</li> <li>Tasks complessi: guadagni modesti o addirittura calo di produttivit\u00e0.</li> <li>Progetti \"greenfield\": AI pi\u00f9 efficace.</li> <li>Progetti \"brownfield\": benefici ridotti.</li> </ul> <p>Questa matrice riassume i risultati:</p> <p></p>"},{"location":"blog/2025/09/24/lai-aiuta-davvero-gli-sviluppatori/#influenza-del-linguaggio-di-programmazione-e-della-dimensione-della-codebase","title":"Influenza del linguaggio di programmazione e della dimensione della codebase","text":"<p>Anche il linguaggio di programmazione \u00e8 uno dei fattori che influenzano i risultati: </p> <ul> <li>Linguaggi popolari, come Python, Java, JS, TS: guadagni consistenti (+10\u201320%) con AI.</li> <li>Linguaggi menu usati, come ad esempio Cobol, Haskell, Elixir: AI poco efficace o persino controproducente.</li> </ul> <p>Inoltre, all\u2019aumentare della dimensione della codebase, l\u2019impatto positivo dell\u2019AI diminuisce. Le cause sono:</p> <ul> <li>Limiti della context window: gli LLM fanno fatica a comprendere basi di codice estese.</li> <li>Il rapporto segnale/rumore aumenta con le dimensioni della codebase.</li> <li>Maggiori dipendenze e logiche strettamente legate al dominio in cui opera l'azienda.</li> </ul> <p>Aumentare la context window non aiuta: esiste questo studio, NoLiMa, che dimostra che anche con context window grandi (es. da 1k a 32k token) le performance dei modelli calano drasticamente:</p> <p></p>"},{"location":"blog/2025/09/24/lai-aiuta-davvero-gli-sviluppatori/#conclusioni","title":"Conclusioni","text":"<p>L\u2019AI pu\u00f2 e deve essere usata per facilitare il lavoro di uno sviluppatore SW, ma l'aumento della sua produttivit\u00e0 non sar\u00e0 scontato. Dipender\u00e0 dalla complessit\u00e0 del task, dalla maturit\u00e0 del progetto (greenfield vs brownfield), dalla popolarit\u00e0 del linguaggio, dalla dimensione della codebase, dai limiti del contesto dei modelli.</p> <p>Per il momento quindi, la possibilit\u00e0 di sostituire gli sviluppatori con degli agenti AI non \u00e8 realistica. Il lavoro dello sviluppatore per\u00f2 si sta evolvendo: come gli artigiani che nel passato realizzavano le loro opere a mano si sono evoluti e oggigiorno utilizzano le macchine, cos\u00ec anche lo sviluppatore non \u00e8 pi\u00f9 un \"tecnico\" del codice, ma diventa un \"pilota\", un \"guidatore\" di strumenti che lo affiancano soprattutto in tutti quei compiti pi\u00f9 ripetitivi e noiosi.</p>"},{"location":"portfolio/","title":"Featured Projects","text":"<p>Welcome to my portfolio of data science and AI projects. Each project demonstrates my expertise in delivering impactful solutions to real-world business challenges.</p> <ul> <li> <p>AI Agent Expert in Italian Legislation</p> <p>AI Assistant Agent expert in Italian legislation regarding the tax credit for Research and Development, Technological Innovation, and Aesthetic Design and Ideation Activities.</p> </li> <li> <p>Specialized Slack Chatbots </p> <p>A suite of specialized chatbots, integrated into Slack and powered by OpenAI APIs: automated email replies, document summaries, and content drafting. The result: faster workflows, fewer repetitive tasks, and more time for high-value work.</p> </li> <li> <p>n8n RAG Chatbot </p> <p>RAG chatbot in n8n with two workflows: a data ingestion pipeline and an inference pipeline for accurate, context-aware answers.</p> </li> </ul>"},{"location":"portfolio/projects/chatbot_slack/","title":"Case Study \u2014 Specialized Chatbots for Smarter Workflows","text":""},{"location":"portfolio/projects/chatbot_slack/#overview","title":"Overview","text":"<p>I developed a set of three specialized chatbots, each focused on a specific task: handling email responses, summarizing documents, and drafting posts or articles.</p> <p>To make the interaction seamless, the bots are integrated into Slack, the platform already used by the client\u2019s team for daily communication. Behind the scenes, the solution relies on OpenAI APIs to harness the power of Large Language Models (LLMs).</p> <p>This project is an example of how LLMs can be integrated into everyday tools and customized to create simple, practical solutions that support real work.</p>"},{"location":"portfolio/projects/chatbot_slack/#technical-challenges-solutions","title":"Technical Challenges &amp; Solutions","text":""},{"location":"portfolio/projects/chatbot_slack/#data-collection-pipeline","title":"Data Collection Pipeline","text":""},{"location":"portfolio/projects/chatbot_slack/#challenges","title":"Challenges:","text":"<ul> <li>Different sources produce different formats (JSON, CSV, HTML, PDFs, APIs).</li> <li>Web crawling requires dealing with rate limits, inconsistent page structures, and data cleaning.</li> </ul>"},{"location":"portfolio/projects/chatbot_slack/#solutions","title":"Solutions:","text":"<ul> <li>Build a multi-source ingestion pipeline with connectors for databases, APIs, and file storage.</li> <li>Use ETL (Extract, Transform, Load) tools or frameworks like Apache Airflow / Prefect to standardize data.</li> <li>Implement web crawlers (e.g., Scrapy, BeautifulSoup) with throttling, retries, and parsing rules.</li> <li>Normalize into a common schema (e.g., JSONL) so that all downstream NLP models receive consistent inputs.</li> <li>Add automated validation layers (checking duplicates, missing values, anomalies) before feeding data to the chatbot.   </li> </ul>"},{"location":"portfolio/projects/chatbot_slack/#cloud-platforms","title":"Cloud Platforms","text":""},{"location":"portfolio/projects/chatbot_slack/#challenges_1","title":"Challenges:","text":"<ul> <li>Sensitive business data must be handled securely when deployed on cloud platforms (AWS, GCP, Azure).</li> <li>Poor authentication/authorization practices can lead to leaks or breaches.</li> <li>Cloud compute costs can escalate quickly if not monitored, especially with GPU workloads.</li> </ul>"},{"location":"portfolio/projects/chatbot_slack/#solutions_1","title":"Solutions:","text":"<ul> <li>Use IAM (Identity and Access Management) with least-privilege policies; apply role-based access controls.</li> <li>Enable multi-factor authentication for administrators and service accounts.</li> <li>Encrypt data both in transit (TLS) and at rest (KMS-managed keys).</li> <li>Implement network isolation (private VPCs, firewalls) to limit attack surface.</li> <li>For cost control:<ul> <li>Use monitoring tools (AWS Cost Explorer, GCP Billing, Azure Cost Management).</li> <li>Set up budgets and alerts for abnormal usage.</li> <li>Use spot/preemptible instances or autoscaling to optimize GPU/CPU usage.</li> </ul> </li> </ul>"},{"location":"portfolio/projects/chatbot_slack/#prompt-engineering","title":"Prompt engineering","text":""},{"location":"portfolio/projects/chatbot_slack/#challenges_2","title":"Challenges:","text":"<ul> <li>LLMs can produce hallucinations or irrelevant answers.</li> <li>Specialized chatbots require controlled tone, compliance with policies, and reliability.</li> <li>Prompts must balance flexibility with strict guardrails.</li> </ul>"},{"location":"portfolio/projects/chatbot_slack/#solutions_2","title":"Solutions:","text":"<ul> <li>Design system instructions that set role, style, and boundaries (e.g., \u201cYou are a legal assistant. Only answer from the company\u2019s approved knowledge base. If unsure, say you don\u2019t know.\u201d).</li> <li>Use few-shot examples in prompts to guide desired responses.</li> <li>Apply guardrails frameworks (e.g., Guardrails AI, LangChain output parsers) to enforce structure and correctness.</li> <li>Combine retrieval-augmented generation (RAG) so answers are grounded in real documents instead of pure model recall.</li> <li>Add confidence estimation and fallback: if the model is uncertain, escalate to human review instead of guessing.</li> </ul>"},{"location":"portfolio/projects/chatbot_slack/#_1","title":"###","text":""},{"location":"portfolio/projects/chatbot_slack/#tech-stack","title":"Tech Stack","text":"<ul> <li>OpenAI</li> <li>Slack API integration</li> <li>Microsoft Azure cloud infrastructure</li> <li>Python backend services</li> <li>FastAPI for RESTful endpoints</li> <li>Docker containerization</li> <li>GitHub Actions for CI/CD pipeline</li> </ul> <ul> <li> <p> Let's have a virtual coffee together!</p> <p>Want to see if we're a match? Let's have a chat and find out. Schedule a free 30-minute strategy session to discuss your AI challenges and explore how we can work together.</p> <p>Book Free Intro Call </p> </li> </ul>"},{"location":"portfolio/projects/n8n_rag_workflow/","title":"N8n rag workflow","text":"<p>title:  RAG Chatbot built with n8n description:  RAG Chatbot composed of two workflows: Data Ingestion, RAG Inference</p>"},{"location":"portfolio/projects/n8n_rag_workflow/#case-study-rag-chatbot-built-with-n8n","title":"Case Study \u2014 RAG Chatbot built with n8n","text":""},{"location":"portfolio/projects/n8n_rag_workflow/#overview","title":"Overview","text":"<p>This project consists of two main workflows:</p> <ul> <li>Data Ingestion Pipeline: responsible for collecting, cleaning, and structuring documents before indexing them into a vector database.</li> <li>RAG Inference Chatbot: manages user queries, retrieves the most relevant context from the vector store, and leverages an LLM to generate accurate, context-aware answers.</li> </ul> <p>Together, these workflows create a streamlined Retrieval-Augmented Generation (RAG) chatbot that provides reliable responses based on the company\u2019s knowledge base.</p>"},{"location":"portfolio/projects/n8n_rag_workflow/#system-architecture","title":"System Architecture","text":"<p>This is the Data Ingestion Workflow block diagram: </p>"},{"location":"portfolio/projects/n8n_rag_workflow/#technical-challenges-solutions","title":"Technical Challenges &amp; Solutions","text":""},{"location":"portfolio/projects/n8n_rag_workflow/#data-collection-pipeline","title":"Data Collection Pipeline","text":""},{"location":"portfolio/projects/n8n_rag_workflow/#challenges","title":"Challenges:","text":"<ul> <li> <p>File acceptance filter: a validation step that checks incoming files against predefined rules (e.g., type, size, required fields). This minimizes the risk of processing corrupted, incomplete, or non-compliant data, ensuring that only valid inputs move forward in the workflow.</p> </li> <li> <p>Logging the result of key nodes: systematically capturing outputs and execution details at critical workflow steps. This provides execution statistics and increases observability, making it easier to monitor performance, troubleshoot errors, and maintain the system over time.</p> </li> </ul>"},{"location":"portfolio/projects/n8n_rag_workflow/#future-improvements","title":"Future Improvements:","text":"<ul> <li>Before embedding a new file check if the same file has already been processed</li> </ul>"},{"location":"portfolio/projects/n8n_rag_workflow/#rag-inference-chatbot","title":"RAG Inference Chatbot","text":""},{"location":"portfolio/projects/n8n_rag_workflow/#challenges_1","title":"Challenges:","text":"<ul> <li> <p>User input validation: Implemented mechanisms to check and sanitize user inputs before passing them to the model. This reduces errors, prevents malicious injections, and ensures that the chatbot or system processes only clean, well-structured data.</p> </li> <li> <p>Prompt engineering (system prompts and instructions): Designed effective prompts that guide the model\u2019s behavior, including system-level instructions and contextual cues. This helps shape responses to be accurate, consistent, and aligned with the desired tone or business goals.</p> </li> <li> <p>Guardrails to avoid hallucinations: Added constraints, filters, and verification steps to reduce the risk of the model generating inaccurate or fabricated information. Fallback strategies are used when confidence is low.</p> </li> </ul>"},{"location":"portfolio/projects/n8n_rag_workflow/#future-improvements_1","title":"Future Improvements:","text":"<ul> <li>Now the workflow is using the n8n chatbot. This can be replaced by a webhook: in this way a separate client application can be used as user interface.</li> </ul>"},{"location":"portfolio/projects/n8n_rag_workflow/#tech-stack","title":"Tech Stack","text":"<ul> <li>N8N</li> <li>Google Drive </li> <li>Google Sheets</li> <li>Pinecone (Vector Database)</li> <li>OpenAI LLM models </li> </ul> <ul> <li> <p> Let's have a virtual coffee together!</p> <p>Want to see if we're a match? Let's have a chat and find out. Schedule a free 30-minute strategy session to discuss your AI challenges and explore how we can work together.</p> <p>Book Free Intro Call </p> </li> </ul>"},{"location":"portfolio/projects/rag_agent/","title":"Case Study \u2014 AI Assistant expert in Italian legislation (tax credit for Research and Development activities)","text":""},{"location":"portfolio/projects/rag_agent/#overview","title":"Overview","text":"<p>I developed an AI Assistant expert in Italian legislation regarding the tax credit for Research and Development, Technological Innovation, and Aesthetic Design and Ideation Activities.</p> <p>He can answer all questions regarding the regulations and, if provided with the data of the projects to be examined, he can classify the activities according to the required criteria.</p> <p>To create the AI \u200b\u200bassistant, an open-source LLM model was fine-tuned and deployed online on the AWS platform using SageMaker. For the RAG component, NoSQL (MongoDB) and vector databases (Qdrant) were used.</p> <p>To control the data collection, model training and deployment processes, pipelines built with ZenML were used.</p>"},{"location":"portfolio/projects/rag_agent/#system-architecture","title":"System Architecture","text":""},{"location":"portfolio/projects/rag_agent/#technical-challenges-solutions","title":"Technical Challenges &amp; Solutions","text":""},{"location":"portfolio/projects/rag_agent/#data-collection-pipeline","title":"Data Collection Pipeline","text":""},{"location":"portfolio/projects/rag_agent/#challenges","title":"Challenges:","text":"<ul> <li>Different sources produce different formats (JSON, CSV, HTML, PDFs, APIs).</li> <li>Web crawling requires dealing with rate limits, inconsistent page structures, and data cleaning.</li> </ul>"},{"location":"portfolio/projects/rag_agent/#solutions","title":"Solutions:","text":"<ul> <li>Build a multi-source ingestion pipeline with connectors for databases, APIs, and file storage.</li> <li>Use ETL (Extract, Transform, Load) tools to standardize data.</li> <li>Implement web crawlers with throttling, retries, and parsing rules.</li> <li>Normalize into a common schema (Pydantic) so that all downstream models receive consistent inputs.</li> </ul>"},{"location":"portfolio/projects/rag_agent/#training-pipeline","title":"Training Pipeline","text":""},{"location":"portfolio/projects/rag_agent/#1-raw-data-cannot-be-directly-used-to-train-the-model","title":"1. Raw data cannot be directly used to train the model","text":"<ul> <li>Business data is usually noisy, unstructured, and inconsistent.</li> <li>Models require formatted datasets with prompt \u2192 response pairs.</li> <li>Low-quality or mislabeled data leads to poor generalization and errors.</li> </ul>"},{"location":"portfolio/projects/rag_agent/#solution","title":"Solution:","text":"<ul> <li>Implement a data preprocessing pipeline: cleaning, deduplication, normalization, and anonymization of sensitive information.</li> <li>Apply quality control checks (sampling, review cycles) to ensure high-quality training data.</li> <li>Maintain a versioned dataset repository (ZenML) to track iterations.</li> </ul>"},{"location":"portfolio/projects/rag_agent/#2-fine-tuning-is-an-iterative-process-and-needs-monitoring","title":"2. Fine-tuning is an iterative process and needs monitoring","text":"<ul> <li>Each training run requires multiple experiments (different learning rates, epochs, prompt structures).</li> <li>Without monitoring, you risk overfitting or underfitting.</li> <li>It\u2019s difficult to know if improvements come from better data, better hyperparameters, or chance.</li> </ul>"},{"location":"portfolio/projects/rag_agent/#solution_1","title":"Solution:","text":"<ul> <li>Use experiment tracking tools (CometML) to log training runs, metrics, and parameters.</li> <li>Define clear evaluation metrics (Training loss, Validation Loss, Gradient Norm).</li> <li>Perform validation on held-out datasets and real-world test cases to avoid overfitting.</li> <li>Automate the process with continuous training pipelines that retrain when new data is available.</li> </ul>"},{"location":"portfolio/projects/rag_agent/#3-fine-tuning-is-gpu-intensive-and-expensive","title":"3. Fine-tuning is GPU intensive and expensive","text":"<ul> <li>LLM fine-tuning requires powerful GPUs (A100/H100) and long runtimes.</li> <li>Training costs scale with dataset size, model size, and experimentation cycles.</li> <li>Running in the cloud without cost control can burn through budgets quickly.</li> </ul>"},{"location":"portfolio/projects/rag_agent/#solution_2","title":"Solution:","text":"<ul> <li>Start with parameter-efficient fine-tuning (PEFT) techniques (LoRA, QLoRA) instead of full fine-tuning \u2192 drastically reduces GPU usage.</li> <li>Use mixed precision training (FP16/BF16) to cut memory and compute costs.</li> <li>Leverage spot/preemptible GPU instances in the cloud for non-critical training runs.</li> <li>Continuously monitor GPU utilization and cost with built-in dashboards (AWS, GCP, Azure).</li> </ul>"},{"location":"portfolio/projects/rag_agent/#example-of-monitored-metrics","title":"Example of Monitored metrics","text":""},{"location":"portfolio/projects/rag_agent/#tech-stack","title":"Tech Stack","text":"<ul> <li>Hugging Face (Model Repository)</li> <li>Llama-3.1-8B</li> <li>MongoDB (NoSQL Database)</li> <li>Qdrant (vector Database)</li> <li>AWS cloud infrastructure</li> <li>AWS SageMaker</li> <li>Python backend services</li> <li>ZenML orchestrator</li> <li>Docker containerization</li> <li>GitHub Actions for CI/CD pipeline</li> </ul> <ul> <li> <p> Let's have a virtual coffee together!</p> <p>Want to see if we're a match? Let's have a chat and find out. Schedule a free 30-minute strategy session to discuss your AI challenges and explore how we can work together.</p> <p>Book Free Intro Call </p> </li> </ul>"},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/category/ai/","title":"AI","text":""},{"location":"blog/category/sw-engineering/","title":"SW Engineering","text":""}]}